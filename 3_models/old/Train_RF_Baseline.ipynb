{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/sw/open/anaconda/3/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "### THIS IS MEANT TO RUN ON NERO - NEEDS TO BE CHANGED IF YOU RUN LOCALLY\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/home/ccorbin/.config/gcloud/application_default_credentials.json' \n",
    "os.environ['GCLOUD_PROJECT'] = 'mining-clinical-decisions' \n",
    "%reload_ext google.cloud.bigquery\n",
    "\n",
    "from google.cloud import bigquery\n",
    "client=bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Long Form Feature Matrix and Cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_cohort = \"\"\"select * from traige_TE.triage_cohort_final_with_labels_complete1vs\"\"\"\n",
    "query_job = client.query(q_cohort)\n",
    "df_cohort = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = df_cohort.sort_values('pat_enc_csn_id_coded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save labels to file\n",
    "train_labels = df_cohort[df_cohort['admit_time'].dt.year < 2018]\n",
    "validation_labels = df_cohort[df_cohort['admit_time'].dt.year == 2018]\n",
    "\n",
    "train_and_val_labels = df_cohort[df_cohort['admit_time'].dt.year < 2019]\n",
    "test_labels = df_cohort[df_cohort['admit_time'].dt.year == 2019]\n",
    "\n",
    "\n",
    "path = '/home/ccorbin/BMI212/data/'\n",
    "train_labels.to_csv(os.path.join(path, 'training_labels.csv'), index=None)\n",
    "validation_labels.to_csv(os.path.join(path, 'validation_labels.csv'), index=None)\n",
    "train_and_val_labels.to_csv(os.path.join(path, 'train_and_val_labels.csv'), index=None)\n",
    "test_labels.to_csv(os.path.join(path, 'test_labels.csv'), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_features = \"\"\"\n",
    "SELECT f.*, EXTRACT(YEAR from f.admit_time) year\n",
    "FROM traige_TE.triage_features_counts_long f\n",
    "RIGHT JOIN traige_TE.triage_cohort_final_with_labels_complete1vs l\n",
    "USING (pat_enc_csn_id_coded)\n",
    "\"\"\"\n",
    "query_job = client.query(q_features)\n",
    "df_features = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = df_features.sort_values('pat_enc_csn_id_coded')\n",
    "df_features_val = df_features[~df_features['feature_type'].isin(['labs_results_test', 'vitals_test'])]\n",
    "df_features_test = df_features[~df_features['feature_type'].isin(['labs_results_train', 'vitals_train'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = df_features_val[df_features_val['year'] < 2018]\n",
    "validation_examples = df_features_val[df_features_val['year'] == 2018]\n",
    "training_and_val_examples = df_features_test[df_features_test['year'] < 2019]\n",
    "test_examples = df_features_test[df_features_test['year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37761"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_and_val_examples['features'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WITH ed_admit_discharge_time AS (\n",
    "SELECT anon_id, pat_enc_csn_id_coded, index_time, max(effective_time_jittered_utc) discharge_time\n",
    "FROM\n",
    "  (SELECT c.anon_id, c.pat_enc_csn_id_coded, c.index_time, adt.effective_time_jittered_utc\n",
    "  FROM `mining-clinical-decisions.abx.interm_cohort_with_no_inf_rules` c\n",
    "  INNER JOIN `shc_core.adt` adt\n",
    "  USING (pat_enc_csn_id_coded)) t\n",
    "GROUP BY anon_id, pat_enc_csn_id_coded, index_time \n",
    ")\n",
    "\n",
    "SELECT ed.*, om.med_description, om.order_start_time_utc\n",
    "FROM ed_admit_discharge_time ed\n",
    "INNER JOIN `shc_core.order_med` om\n",
    "USING (anon_id)\n",
    "INNER JOIN `mining-clinical-decisions.abx.abx_types` abx_types \n",
    "USING (med_description)\n",
    "WHERE om.order_start_time_utc BETWEEN index_time AND TIMESTAMP_ADD(index_time, INTERVAL 14*24 HOUR) \n",
    "AND abx_types.is_include_abx = 0 AND abx_types.affects_not_infected_label = 1\n",
    "ORDER BY anon_id, pat_enc_csn_id_coded, om.order_start_time_utc\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, save_npz\n",
    "import pdb\n",
    "\n",
    "def build_vocab(data):\n",
    "    \"\"\"Builds vocabulary for of terms from the data. Assigns each unique term to a monotonically increasing integer.\"\"\"\n",
    "    vocabulary = {}\n",
    "    for i, d in enumerate(data):\n",
    "        for j, term in enumerate(d):\n",
    "            vocabulary.setdefault(term, len(vocabulary))\n",
    "    return vocabulary\n",
    "\n",
    "def create_sparse_feature_matrix(train_data, apply_data):\n",
    "    \"\"\"Creates sparse matrix efficiently from long form dataframe.  We build a vocabulary\n",
    "       from the training set, then apply vocab to the apply_set\n",
    "       \n",
    "       Parameters\n",
    "       ----------\n",
    "       train_data : long form pandas DataFrame\n",
    "           Data to use to build vocabulary\n",
    "       apply_data : long form pandas DataFrame\n",
    "           Data to transform to sparse matrix for input to ML models\n",
    "    \n",
    "       Returns\n",
    "       -------\n",
    "       csr_data : scipy csr_matrix\n",
    "           Sparse matrix version of apply_data to feed into ML models. \n",
    "    \"\"\"\n",
    "    \n",
    "    train_features = train_data.groupby('pat_enc_csn_id_coded').agg({\n",
    "        'features' : lambda x: list(x),\n",
    "        'values' : lambda x: list(x)}).reset_index()\n",
    "    train_feature_names = [doc for doc in train_features.features.values]\n",
    "    train_feature_values = [doc for doc in train_features['values'].values]\n",
    "    train_csns = [csn for csn in train_features.pat_enc_csn_id_coded.values]\n",
    "    \n",
    "    apply_features = apply_data.groupby('pat_enc_csn_id_coded').agg({\n",
    "        'features' : lambda x: list(x),\n",
    "        'values' : lambda x: list(x)}).reset_index()\n",
    "    apply_features_names = [doc for doc in apply_features.features.values]\n",
    "    apply_features_values = [doc for doc in apply_features['values'].values]\n",
    "    apply_csns = [csn for csn in apply_features.pat_enc_csn_id_coded.values]\n",
    "\n",
    "    \n",
    "    vocabulary = build_vocab(train_feature_names)\n",
    "    indptr = [0]\n",
    "    indices = []\n",
    "    data = []\n",
    "    for i, d in enumerate(apply_features_names):\n",
    "        for j, term in enumerate(d):\n",
    "            if term not in vocabulary:\n",
    "                continue\n",
    "            else:\n",
    "                indices.append(vocabulary[term])\n",
    "                data.append(apply_features_values[i][j])\n",
    "            if j == 0:\n",
    "                # Add zero to data and max index in vocabulary to indices in case max feature indice isn't in apply features.\n",
    "                indices.append(len(vocabulary)-1)\n",
    "                data.append(0)\n",
    "        indptr.append(len(indices))\n",
    "    \n",
    "    csr_data = csr_matrix((data, indices, indptr), dtype=float)\n",
    "    \n",
    "    return csr_data, apply_csns, vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_csr, train_csns = create_sparse_feature_matrix(training_examples, training_examples)\n",
    "# validation_csr, val_csns = create_sparse_feature_matrix(training_examples, validation_examples)\n",
    "train_and_val_csr, train_and_val_csns, train_and_val_vocab = create_sparse_feature_matrix(training_and_val_examples, training_and_val_examples)\n",
    "test_csr, test_csns, test_and_val_vocab = create_sparse_feature_matrix(training_and_val_examples, test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10096, 37761)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csr.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13500"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(training_and_val_examples['features'].values).difference(set(test_examples['features'].values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28472"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(test_examples['features'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22037"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_csns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels['pat_enc_csn_id_coded'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a, b in zip(train_labels['pat_enc_csn_id_coded'].values, train_csns):\n",
    "    assert a == b\n",
    "for a, b in zip(validation_labels['pat_enc_csn_id_coded'].values, val_csns):\n",
    "    assert a == b\n",
    "for a, b in zip(train_and_val_labels['pat_enc_csn_id_coded'].values, train_and_val_csns):\n",
    "    assert a == b\n",
    "for a, b in zip(test_labels['pat_enc_csn_id_coded'].values, test_csns):\n",
    "    assert a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, save_npz\n",
    "\n",
    "import os\n",
    "path = '/home/ccorbin/BMI212/data/'\n",
    "save_npz(os.path.join(path, 'training_examples.npz'), train_csr)\n",
    "save_npz(os.path.join(path, 'validation_examples.npz'), validation_csr)\n",
    "save_npz(os.path.join(path, 'training_and_val_examples.npz'), train_and_val_csr)\n",
    "save_npz(os.path.join(path, 'test_examples.npz'), test_csr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Create dictionary of all unique features and the set of csns that have the feature\n",
    "# feature_dict = {}\n",
    "# for feature, csn in zip(df_features.feature_name.values, df_features.pat_enc_csn_id_coded.values):\n",
    "#     if feature in feature_dict:\n",
    "#         feature_dict[feature].add(csn)\n",
    "#     else:\n",
    "#         feature_dict[feature] = set()\n",
    "#         feature_dict[feature].add(csn)\n",
    "# ### Remove features where less than 50 patients have that features\n",
    "# feature_dict = {key : value for key, value in feature_dict.items() if len(value) >= 50}\n",
    "\n",
    "# # Get df into document format where we have a list of csn's that each are a list of features. \n",
    "# # index - index of each feature\n",
    "# # indices - list of indexes in order you loop through csn's and features\n",
    "# # indptr - num of indices in a document\n",
    "# # data - the value for each index\n",
    "\n",
    "# ### Save features matrix in sparse matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "docs = feature_names\n",
    "indptr = [0]\n",
    "indices = []\n",
    "data = []\n",
    "vocabulary = {}\n",
    "for i, d in enumerate(docs):\n",
    "    for j, term in enumerate(d):\n",
    "        index = vocabulary.setdefault(term, len(vocabulary))\n",
    "        indices.append(index)\n",
    "        data.append(feature_values[i][j])\n",
    "    indptr.append(len(indices))\n",
    "\n",
    "test_csr = csr_matrix((data, indices, indptr), dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41654, 41974)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csr.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv('features_long.csv', index=None)\n",
    "df_cohort.to_csv('cohort.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_types = set(['demo', 'Lab', 'Meds', 'Imaging', 'Procedures', 'Diagnosis', 'vitals_train', 'labs_results_train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly Sample 5000 examples from our 30k - actually just run full thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23626"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_full = df_features[df_features['feature_type'].isin(feature_types)]\n",
    "df_cohort_small = df_cohort.sample(n=5000)\n",
    "df_cohort_small = df_cohort \n",
    "csns = set(df_cohort_small['pat_enc_csn_id_coded'].values)\n",
    "len(csns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jc_uid</th>\n",
       "      <th>pat_enc_csn_id_coded</th>\n",
       "      <th>admit_time</th>\n",
       "      <th>features</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Diagnosis</th>\n",
       "      <td>2998309</td>\n",
       "      <td>2998309</td>\n",
       "      <td>2998309</td>\n",
       "      <td>2998309</td>\n",
       "      <td>2998309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Imaging</th>\n",
       "      <td>220761</td>\n",
       "      <td>220761</td>\n",
       "      <td>220761</td>\n",
       "      <td>220761</td>\n",
       "      <td>220761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lab</th>\n",
       "      <td>787576</td>\n",
       "      <td>787576</td>\n",
       "      <td>787576</td>\n",
       "      <td>787576</td>\n",
       "      <td>787576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Meds</th>\n",
       "      <td>1434271</td>\n",
       "      <td>1434271</td>\n",
       "      <td>1434271</td>\n",
       "      <td>1434271</td>\n",
       "      <td>1434271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Procedures</th>\n",
       "      <td>32401</td>\n",
       "      <td>32401</td>\n",
       "      <td>32401</td>\n",
       "      <td>32401</td>\n",
       "      <td>32401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>demo</th>\n",
       "      <td>533024</td>\n",
       "      <td>533024</td>\n",
       "      <td>533024</td>\n",
       "      <td>533024</td>\n",
       "      <td>533024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labs_results_train</th>\n",
       "      <td>308754</td>\n",
       "      <td>308754</td>\n",
       "      <td>308754</td>\n",
       "      <td>308754</td>\n",
       "      <td>308754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vitals_train</th>\n",
       "      <td>333645</td>\n",
       "      <td>333645</td>\n",
       "      <td>333645</td>\n",
       "      <td>333645</td>\n",
       "      <td>333645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     jc_uid  pat_enc_csn_id_coded  admit_time  features  \\\n",
       "feature_type                                                              \n",
       "Diagnosis           2998309               2998309     2998309   2998309   \n",
       "Imaging              220761                220761      220761    220761   \n",
       "Lab                  787576                787576      787576    787576   \n",
       "Meds                1434271               1434271     1434271   1434271   \n",
       "Procedures            32401                 32401       32401     32401   \n",
       "demo                 533024                533024      533024    533024   \n",
       "labs_results_train   308754                308754      308754    308754   \n",
       "vitals_train         333645                333645      333645    333645   \n",
       "\n",
       "                     values  \n",
       "feature_type                 \n",
       "Diagnosis           2998309  \n",
       "Imaging              220761  \n",
       "Lab                  787576  \n",
       "Meds                1434271  \n",
       "Procedures            32401  \n",
       "demo                 533024  \n",
       "labs_results_train   308754  \n",
       "vitals_train         333645  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_full.groupby('feature_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_small = df_features_full[df_features_full['pat_enc_csn_id_coded'].isin(csns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4736369"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_features_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Features (will be very memory intensive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_features_small.pivot(index='pat_enc_csn_id_coded',\n",
    "                          columns='features',\n",
    "                          values='values').fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23626, 84631)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge features and cohort labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(df_cohort_small,\n",
    "                features,\n",
    "                on='pat_enc_csn_id_coded',\n",
    "                how='left').fillna(0.0) # if no features there means none of these things ordered and count should be zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['admit_time'] >= '2017-06-30'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test based on time where 2017 is test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['admit_time'] < '2017-06-30']\n",
    "data_test = data[data['admit_time'] >= '2017-07-01']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create X_train, X_test, Y_train Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train[features.columns].values\n",
    "X_test = data_test[features.columns].values\n",
    "\n",
    "Y_train = data_train['label'].values\n",
    "Y_test = data_test['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just use skearns Random Forest For Now (Need my own env to install LGBM - getting help from SRCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Using default params except num_trees=1000\n",
    "rf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "rf.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8181121918378957\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict_proba(X_test)\n",
    "auroc = roc_auc_score(Y_test, predictions[:, 1])\n",
    "print(auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3656"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "out_dict['yhat'] = predictions[:, 1]\n",
    "out_dict['label'] = Y_test\n",
    "df_out = pd.DataFrame(out_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('rf_yhats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13320568927789933"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "487/3656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84631,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>imps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83959</th>\n",
       "      <td>Weight1</td>\n",
       "      <td>0.011707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84616</th>\n",
       "      <td>age1</td>\n",
       "      <td>0.011659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34256</th>\n",
       "      <td>Height1</td>\n",
       "      <td>0.010714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68215</th>\n",
       "      <td>RR_7</td>\n",
       "      <td>0.006511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38000</th>\n",
       "      <td>IMGDXCH1</td>\n",
       "      <td>0.005963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37906</th>\n",
       "      <td>IMGCTHSC</td>\n",
       "      <td>0.005090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70646</th>\n",
       "      <td>SBP_0</td>\n",
       "      <td>0.004514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68211</th>\n",
       "      <td>RR_3</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44237</th>\n",
       "      <td>LABMETC</td>\n",
       "      <td>0.004242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43562</th>\n",
       "      <td>LABCBCD</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67552</th>\n",
       "      <td>Pulse_9</td>\n",
       "      <td>0.004073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73693</th>\n",
       "      <td>SpO2_6</td>\n",
       "      <td>0.004034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68214</th>\n",
       "      <td>RR_6</td>\n",
       "      <td>0.003759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73687</th>\n",
       "      <td>SpO2_0</td>\n",
       "      <td>0.003538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44668</th>\n",
       "      <td>LABTYPSNI</td>\n",
       "      <td>0.003395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21528</th>\n",
       "      <td>DBP_9</td>\n",
       "      <td>0.003213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68213</th>\n",
       "      <td>RR_5</td>\n",
       "      <td>0.003118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44675</th>\n",
       "      <td>LABUAPRN</td>\n",
       "      <td>0.003012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67551</th>\n",
       "      <td>Pulse_8</td>\n",
       "      <td>0.002910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43492</th>\n",
       "      <td>LABASI</td>\n",
       "      <td>0.002879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21518</th>\n",
       "      <td>DBP_0</td>\n",
       "      <td>0.002831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84622</th>\n",
       "      <td>medis1</td>\n",
       "      <td>0.002803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68209</th>\n",
       "      <td>RR_1</td>\n",
       "      <td>0.002732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55704</th>\n",
       "      <td>ONDANSETRON HCL (PF) 4 MG/2 ML INJ SOLN</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70656</th>\n",
       "      <td>SBP_9</td>\n",
       "      <td>0.002677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68208</th>\n",
       "      <td>RR_0</td>\n",
       "      <td>0.002647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43486</th>\n",
       "      <td>LABARI</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73691</th>\n",
       "      <td>SpO2_4</td>\n",
       "      <td>0.002575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44330</th>\n",
       "      <td>LABPT</td>\n",
       "      <td>0.002567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21527</th>\n",
       "      <td>DBP_8</td>\n",
       "      <td>0.002553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      features      imps\n",
       "83959                                  Weight1  0.011707\n",
       "84616                                     age1  0.011659\n",
       "34256                                  Height1  0.010714\n",
       "68215                                     RR_7  0.006511\n",
       "38000                                 IMGDXCH1  0.005963\n",
       "37906                                 IMGCTHSC  0.005090\n",
       "70646                                    SBP_0  0.004514\n",
       "68211                                     RR_3  0.004277\n",
       "44237                                  LABMETC  0.004242\n",
       "43562                                  LABCBCD  0.004228\n",
       "67552                                  Pulse_9  0.004073\n",
       "73693                                   SpO2_6  0.004034\n",
       "68214                                     RR_6  0.003759\n",
       "73687                                   SpO2_0  0.003538\n",
       "44668                                LABTYPSNI  0.003395\n",
       "21528                                    DBP_9  0.003213\n",
       "68213                                     RR_5  0.003118\n",
       "44675                                 LABUAPRN  0.003012\n",
       "67551                                  Pulse_8  0.002910\n",
       "43492                                   LABASI  0.002879\n",
       "21518                                    DBP_0  0.002831\n",
       "84622                                   medis1  0.002803\n",
       "68209                                     RR_1  0.002732\n",
       "55704  ONDANSETRON HCL (PF) 4 MG/2 ML INJ SOLN  0.002688\n",
       "70656                                    SBP_9  0.002677\n",
       "68208                                     RR_0  0.002647\n",
       "43486                                   LABARI  0.002646\n",
       "73691                                   SpO2_4  0.002575\n",
       "44330                                    LABPT  0.002567\n",
       "21527                                    DBP_8  0.002553"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'features' : features.columns, 'imps' : rf.feature_importances_}).sort_values('imps', ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.4-0.m71",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.4-0:m71"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
